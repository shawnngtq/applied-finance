{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Introduction to fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import sys\n",
    "FILEPATH='/home/anonymous/Documents/github/data-science-toolbox/notebooks'\n",
    "\n",
    "if FILEPATH not in sys.path:\n",
    "    sys.path.append(FILEPATH)\n",
    "\n",
    "import pandas_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/anonymous/anaconda3/lib/python36.zip',\n",
       " '/home/anonymous/anaconda3/lib/python3.6',\n",
       " '/home/anonymous/anaconda3/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/home/anonymous/.local/lib/python3.6/site-packages',\n",
       " '/home/anonymous/anaconda3/lib/python3.6/site-packages',\n",
       " '/home/anonymous/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/home/anonymous/.ipython',\n",
       " '/home/anonymous/Documents/github/data-science-toolbox/notebooks']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_common.config_pandas_display()\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printListItemLength(List):\n",
    "    for item in List:\n",
    "        print(len(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8000 entries, 0 to 7999\n",
      "Data columns (total 31 columns):\n",
      "Time      8000 non-null int64\n",
      "V1        8000 non-null float64\n",
      "V2        8000 non-null float64\n",
      "V3        8000 non-null float64\n",
      "V4        8000 non-null float64\n",
      "V5        8000 non-null float64\n",
      "V6        8000 non-null float64\n",
      "V7        8000 non-null float64\n",
      "V8        8000 non-null float64\n",
      "V9        8000 non-null float64\n",
      "V10       8000 non-null float64\n",
      "V11       8000 non-null float64\n",
      "V12       8000 non-null float64\n",
      "V13       8000 non-null float64\n",
      "V14       8000 non-null float64\n",
      "V15       8000 non-null float64\n",
      "V16       8000 non-null float64\n",
      "V17       8000 non-null float64\n",
      "V18       8000 non-null float64\n",
      "V19       8000 non-null float64\n",
      "V20       8000 non-null float64\n",
      "V21       8000 non-null float64\n",
      "V22       8000 non-null float64\n",
      "V23       8000 non-null float64\n",
      "V24       8000 non-null float64\n",
      "V25       8000 non-null float64\n",
      "V26       8000 non-null float64\n",
      "V27       8000 non-null float64\n",
      "V28       8000 non-null float64\n",
      "Amount    8000 non-null float64\n",
      "Class     8000 non-null int64\n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/chapter_1/creditcard_sampledata.csv', index_col=0)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>1.212511</td>\n",
       "      <td>-0.099054</td>\n",
       "      <td>-1.192094</td>\n",
       "      <td>0.286324</td>\n",
       "      <td>2.160516</td>\n",
       "      <td>3.616314</td>\n",
       "      <td>-0.404207</td>\n",
       "      <td>0.842331</td>\n",
       "      <td>0.169360</td>\n",
       "      <td>-0.030522</td>\n",
       "      <td>-0.541957</td>\n",
       "      <td>0.237212</td>\n",
       "      <td>-0.218130</td>\n",
       "      <td>0.197437</td>\n",
       "      <td>-0.147850</td>\n",
       "      <td>-0.097830</td>\n",
       "      <td>-0.510053</td>\n",
       "      <td>-0.070939</td>\n",
       "      <td>0.355171</td>\n",
       "      <td>0.014777</td>\n",
       "      <td>-0.167496</td>\n",
       "      <td>-0.494695</td>\n",
       "      <td>-0.149785</td>\n",
       "      <td>1.011227</td>\n",
       "      <td>0.883548</td>\n",
       "      <td>-0.329434</td>\n",
       "      <td>0.020370</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>34.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>-0.658305</td>\n",
       "      <td>0.406791</td>\n",
       "      <td>2.037461</td>\n",
       "      <td>-0.291298</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>-0.350857</td>\n",
       "      <td>0.945373</td>\n",
       "      <td>-0.172560</td>\n",
       "      <td>0.025133</td>\n",
       "      <td>-0.778135</td>\n",
       "      <td>-0.196290</td>\n",
       "      <td>0.632955</td>\n",
       "      <td>0.374025</td>\n",
       "      <td>-0.531597</td>\n",
       "      <td>-0.615063</td>\n",
       "      <td>-0.518078</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>-1.288954</td>\n",
       "      <td>-0.797804</td>\n",
       "      <td>0.064133</td>\n",
       "      <td>-0.156096</td>\n",
       "      <td>-0.238805</td>\n",
       "      <td>0.089877</td>\n",
       "      <td>0.421195</td>\n",
       "      <td>-0.352487</td>\n",
       "      <td>0.074783</td>\n",
       "      <td>-0.094192</td>\n",
       "      <td>-0.092493</td>\n",
       "      <td>54.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0    64  1.212511 -0.099054 -1.192094  0.286324  2.160516  3.616314 -0.404207   \n",
       "1    64 -0.658305  0.406791  2.037461 -0.291298  0.147910 -0.350857  0.945373   \n",
       "\n",
       "         V8        V9       V10       V11       V12       V13       V14  \\\n",
       "0  0.842331  0.169360 -0.030522 -0.541957  0.237212 -0.218130  0.197437   \n",
       "1 -0.172560  0.025133 -0.778135 -0.196290  0.632955  0.374025 -0.531597   \n",
       "\n",
       "        V15       V16       V17       V18       V19       V20       V21  \\\n",
       "0 -0.147850 -0.097830 -0.510053 -0.070939  0.355171  0.014777 -0.167496   \n",
       "1 -0.615063 -0.518078  0.003881 -1.288954 -0.797804  0.064133 -0.156096   \n",
       "\n",
       "        V22       V23       V24       V25       V26       V27       V28  \\\n",
       "0 -0.494695 -0.149785  1.011227  0.883548 -0.329434  0.020370  0.017037   \n",
       "1 -0.238805  0.089877  0.421195 -0.352487  0.074783 -0.094192 -0.092493   \n",
       "\n",
       "   Amount  Class  \n",
       "0   34.70      0  \n",
       "1   54.99      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5050 entries, 258647 to 63421\n",
      "Data columns (total 30 columns):\n",
      "V1        5050 non-null float64\n",
      "V2        5050 non-null float64\n",
      "V3        5050 non-null float64\n",
      "V4        5050 non-null float64\n",
      "V5        5050 non-null float64\n",
      "V6        5050 non-null float64\n",
      "V7        5050 non-null float64\n",
      "V8        5050 non-null float64\n",
      "V9        5050 non-null float64\n",
      "V10       5050 non-null float64\n",
      "V11       5050 non-null float64\n",
      "V12       5050 non-null float64\n",
      "V13       5050 non-null float64\n",
      "V14       5050 non-null float64\n",
      "V15       5050 non-null float64\n",
      "V16       5050 non-null float64\n",
      "V17       5050 non-null float64\n",
      "V18       5050 non-null float64\n",
      "V19       5050 non-null float64\n",
      "V20       5050 non-null float64\n",
      "V21       5050 non-null float64\n",
      "V22       5050 non-null float64\n",
      "V23       5050 non-null float64\n",
      "V24       5050 non-null float64\n",
      "V25       5050 non-null float64\n",
      "V26       5050 non-null float64\n",
      "V27       5050 non-null float64\n",
      "V28       5050 non-null float64\n",
      "Amount    5050 non-null float64\n",
      "Class     5050 non-null int64\n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1_2 = pd.read_csv('data/chapter_1/creditcard_sampledata_3.csv', index_col=0)\n",
    "df1_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5050, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258647</th>\n",
       "      <td>1.725265</td>\n",
       "      <td>-1.337256</td>\n",
       "      <td>-1.012687</td>\n",
       "      <td>-0.361656</td>\n",
       "      <td>-1.431611</td>\n",
       "      <td>-1.098681</td>\n",
       "      <td>-0.842274</td>\n",
       "      <td>-0.026594</td>\n",
       "      <td>-0.032409</td>\n",
       "      <td>0.215113</td>\n",
       "      <td>1.618952</td>\n",
       "      <td>-0.654046</td>\n",
       "      <td>-1.442665</td>\n",
       "      <td>-1.546538</td>\n",
       "      <td>-0.230008</td>\n",
       "      <td>1.785539</td>\n",
       "      <td>1.419793</td>\n",
       "      <td>0.071666</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>0.275911</td>\n",
       "      <td>0.414524</td>\n",
       "      <td>0.793434</td>\n",
       "      <td>0.028887</td>\n",
       "      <td>0.419421</td>\n",
       "      <td>-0.367529</td>\n",
       "      <td>-0.155634</td>\n",
       "      <td>-0.015768</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>189.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69263</th>\n",
       "      <td>0.683254</td>\n",
       "      <td>-1.681875</td>\n",
       "      <td>0.533349</td>\n",
       "      <td>-0.326064</td>\n",
       "      <td>-1.455603</td>\n",
       "      <td>0.101832</td>\n",
       "      <td>-0.520590</td>\n",
       "      <td>0.114036</td>\n",
       "      <td>-0.601760</td>\n",
       "      <td>0.444011</td>\n",
       "      <td>1.521570</td>\n",
       "      <td>0.499202</td>\n",
       "      <td>-0.127849</td>\n",
       "      <td>-0.237253</td>\n",
       "      <td>-0.752351</td>\n",
       "      <td>0.667190</td>\n",
       "      <td>0.724785</td>\n",
       "      <td>-1.736615</td>\n",
       "      <td>0.702088</td>\n",
       "      <td>0.638186</td>\n",
       "      <td>0.116898</td>\n",
       "      <td>-0.304605</td>\n",
       "      <td>-0.125547</td>\n",
       "      <td>0.244848</td>\n",
       "      <td>0.069163</td>\n",
       "      <td>-0.460712</td>\n",
       "      <td>-0.017068</td>\n",
       "      <td>0.063542</td>\n",
       "      <td>315.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "258647  1.725265 -1.337256 -1.012687 -0.361656 -1.431611 -1.098681 -0.842274   \n",
       "69263   0.683254 -1.681875  0.533349 -0.326064 -1.455603  0.101832 -0.520590   \n",
       "\n",
       "              V8        V9       V10       V11       V12       V13       V14  \\\n",
       "258647 -0.026594 -0.032409  0.215113  1.618952 -0.654046 -1.442665 -1.546538   \n",
       "69263   0.114036 -0.601760  0.444011  1.521570  0.499202 -0.127849 -0.237253   \n",
       "\n",
       "             V15       V16       V17       V18       V19       V20       V21  \\\n",
       "258647 -0.230008  1.785539  1.419793  0.071666  0.233031  0.275911  0.414524   \n",
       "69263  -0.752351  0.667190  0.724785 -1.736615  0.702088  0.638186  0.116898   \n",
       "\n",
       "             V22       V23       V24       V25       V26       V27       V28  \\\n",
       "258647  0.793434  0.028887  0.419421 -0.367529 -0.155634 -0.015768  0.010790   \n",
       "69263  -0.304605 -0.125547  0.244848  0.069163 -0.460712 -0.017068  0.063542   \n",
       "\n",
       "        Amount  Class  \n",
       "258647  189.00      0  \n",
       "69263   315.17      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "      <td>5050.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.014675</td>\n",
       "      <td>0.044325</td>\n",
       "      <td>-0.035144</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>-0.046625</td>\n",
       "      <td>-0.046340</td>\n",
       "      <td>-0.043020</td>\n",
       "      <td>-0.008398</td>\n",
       "      <td>-0.027331</td>\n",
       "      <td>-0.056943</td>\n",
       "      <td>0.035342</td>\n",
       "      <td>-0.052371</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>-0.063824</td>\n",
       "      <td>-0.027567</td>\n",
       "      <td>-0.044949</td>\n",
       "      <td>-0.070704</td>\n",
       "      <td>-0.037026</td>\n",
       "      <td>-0.007536</td>\n",
       "      <td>-0.000940</td>\n",
       "      <td>-0.003516</td>\n",
       "      <td>-0.009421</td>\n",
       "      <td>-0.004147</td>\n",
       "      <td>-0.001200</td>\n",
       "      <td>-0.003314</td>\n",
       "      <td>-0.004836</td>\n",
       "      <td>-0.005726</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>86.117232</td>\n",
       "      <td>0.009901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.952784</td>\n",
       "      <td>1.558235</td>\n",
       "      <td>1.691458</td>\n",
       "      <td>1.493592</td>\n",
       "      <td>1.321320</td>\n",
       "      <td>1.254301</td>\n",
       "      <td>1.338170</td>\n",
       "      <td>1.323247</td>\n",
       "      <td>1.134506</td>\n",
       "      <td>1.278092</td>\n",
       "      <td>1.105792</td>\n",
       "      <td>1.259155</td>\n",
       "      <td>0.994961</td>\n",
       "      <td>1.190900</td>\n",
       "      <td>0.905586</td>\n",
       "      <td>1.031225</td>\n",
       "      <td>1.234009</td>\n",
       "      <td>0.894977</td>\n",
       "      <td>0.827070</td>\n",
       "      <td>0.715765</td>\n",
       "      <td>0.756735</td>\n",
       "      <td>0.724749</td>\n",
       "      <td>0.601276</td>\n",
       "      <td>0.599400</td>\n",
       "      <td>0.517363</td>\n",
       "      <td>0.481913</td>\n",
       "      <td>0.411055</td>\n",
       "      <td>0.302719</td>\n",
       "      <td>227.210259</td>\n",
       "      <td>0.099020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-25.266355</td>\n",
       "      <td>-18.701995</td>\n",
       "      <td>-26.823673</td>\n",
       "      <td>-4.575708</td>\n",
       "      <td>-18.664251</td>\n",
       "      <td>-6.357009</td>\n",
       "      <td>-23.783470</td>\n",
       "      <td>-41.484823</td>\n",
       "      <td>-8.504285</td>\n",
       "      <td>-17.141514</td>\n",
       "      <td>-3.469084</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-3.539561</td>\n",
       "      <td>-15.297656</td>\n",
       "      <td>-3.875765</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-21.338195</td>\n",
       "      <td>-8.484449</td>\n",
       "      <td>-4.038451</td>\n",
       "      <td>-13.421949</td>\n",
       "      <td>-20.262054</td>\n",
       "      <td>-5.532541</td>\n",
       "      <td>-17.026156</td>\n",
       "      <td>-2.307453</td>\n",
       "      <td>-3.308049</td>\n",
       "      <td>-1.715640</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-5.048979</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.926226</td>\n",
       "      <td>-0.589562</td>\n",
       "      <td>-0.873696</td>\n",
       "      <td>-0.871759</td>\n",
       "      <td>-0.733235</td>\n",
       "      <td>-0.777552</td>\n",
       "      <td>-0.571678</td>\n",
       "      <td>-0.211263</td>\n",
       "      <td>-0.651215</td>\n",
       "      <td>-0.541561</td>\n",
       "      <td>-0.752762</td>\n",
       "      <td>-0.438689</td>\n",
       "      <td>-0.639214</td>\n",
       "      <td>-0.462520</td>\n",
       "      <td>-0.601438</td>\n",
       "      <td>-0.490668</td>\n",
       "      <td>-0.490088</td>\n",
       "      <td>-0.508041</td>\n",
       "      <td>-0.471003</td>\n",
       "      <td>-0.212240</td>\n",
       "      <td>-0.231508</td>\n",
       "      <td>-0.558904</td>\n",
       "      <td>-0.161166</td>\n",
       "      <td>-0.354973</td>\n",
       "      <td>-0.316947</td>\n",
       "      <td>-0.331584</td>\n",
       "      <td>-0.070963</td>\n",
       "      <td>-0.052133</td>\n",
       "      <td>4.990000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.088726</td>\n",
       "      <td>0.168377</td>\n",
       "      <td>-0.027034</td>\n",
       "      <td>-0.060932</td>\n",
       "      <td>-0.304225</td>\n",
       "      <td>0.036753</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>-0.052724</td>\n",
       "      <td>-0.109888</td>\n",
       "      <td>-0.032953</td>\n",
       "      <td>0.144052</td>\n",
       "      <td>-0.019056</td>\n",
       "      <td>0.032090</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>0.064560</td>\n",
       "      <td>-0.077191</td>\n",
       "      <td>-0.021247</td>\n",
       "      <td>-0.004843</td>\n",
       "      <td>-0.062039</td>\n",
       "      <td>-0.035204</td>\n",
       "      <td>-0.013332</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.038272</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>-0.059882</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.012842</td>\n",
       "      <td>20.260000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.310062</td>\n",
       "      <td>0.809298</td>\n",
       "      <td>1.017166</td>\n",
       "      <td>0.763626</td>\n",
       "      <td>0.603678</td>\n",
       "      <td>0.356664</td>\n",
       "      <td>0.594029</td>\n",
       "      <td>0.313264</td>\n",
       "      <td>0.568374</td>\n",
       "      <td>0.437051</td>\n",
       "      <td>0.759681</td>\n",
       "      <td>0.623239</td>\n",
       "      <td>0.683348</td>\n",
       "      <td>0.466251</td>\n",
       "      <td>0.607702</td>\n",
       "      <td>0.516420</td>\n",
       "      <td>0.389950</td>\n",
       "      <td>0.469353</td>\n",
       "      <td>0.458362</td>\n",
       "      <td>0.124908</td>\n",
       "      <td>0.196481</td>\n",
       "      <td>0.509243</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0.441278</td>\n",
       "      <td>0.348177</td>\n",
       "      <td>0.228486</td>\n",
       "      <td>0.095662</td>\n",
       "      <td>0.077357</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.422508</td>\n",
       "      <td>14.323254</td>\n",
       "      <td>3.760965</td>\n",
       "      <td>11.885313</td>\n",
       "      <td>9.880564</td>\n",
       "      <td>7.473970</td>\n",
       "      <td>9.288494</td>\n",
       "      <td>16.633103</td>\n",
       "      <td>8.054123</td>\n",
       "      <td>12.562347</td>\n",
       "      <td>9.939820</td>\n",
       "      <td>4.846452</td>\n",
       "      <td>3.579906</td>\n",
       "      <td>6.634483</td>\n",
       "      <td>3.363685</td>\n",
       "      <td>3.620831</td>\n",
       "      <td>6.024397</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>4.851255</td>\n",
       "      <td>10.150611</td>\n",
       "      <td>19.283602</td>\n",
       "      <td>5.805795</td>\n",
       "      <td>13.218751</td>\n",
       "      <td>3.535179</td>\n",
       "      <td>3.590787</td>\n",
       "      <td>2.961609</td>\n",
       "      <td>4.623508</td>\n",
       "      <td>9.876371</td>\n",
       "      <td>4584.880000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                V1           V2           V3           V4           V5  \\\n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000   \n",
       "mean     -0.014675     0.044325    -0.035144     0.002494    -0.046625   \n",
       "std       1.952784     1.558235     1.691458     1.493592     1.321320   \n",
       "min     -25.266355   -18.701995   -26.823673    -4.575708   -18.664251   \n",
       "25%      -0.926226    -0.589562    -0.873696    -0.871759    -0.733235   \n",
       "50%       0.009592     0.088726     0.168377    -0.027034    -0.060932   \n",
       "75%       1.310062     0.809298     1.017166     0.763626     0.603678   \n",
       "max       2.422508    14.323254     3.760965    11.885313     9.880564   \n",
       "\n",
       "                V6           V7           V8           V9          V10  \\\n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000   \n",
       "mean     -0.046340    -0.043020    -0.008398    -0.027331    -0.056943   \n",
       "std       1.254301     1.338170     1.323247     1.134506     1.278092   \n",
       "min      -6.357009   -23.783470   -41.484823    -8.504285   -17.141514   \n",
       "25%      -0.777552    -0.571678    -0.211263    -0.651215    -0.541561   \n",
       "50%      -0.304225     0.036753     0.000985    -0.052724    -0.109888   \n",
       "75%       0.356664     0.594029     0.313264     0.568374     0.437051   \n",
       "max       7.473970     9.288494    16.633103     8.054123    12.562347   \n",
       "\n",
       "               V11          V12          V13          V14          V15  \\\n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000   \n",
       "mean      0.035342    -0.052371     0.003131    -0.063824    -0.027567   \n",
       "std       1.105792     1.259155     0.994961     1.190900     0.905586   \n",
       "min      -3.469084   -18.683715    -3.539561   -15.297656    -3.875765   \n",
       "25%      -0.752762    -0.438689    -0.639214    -0.462520    -0.601438   \n",
       "50%      -0.032953     0.144052    -0.019056     0.032090     0.013126   \n",
       "75%       0.759681     0.623239     0.683348     0.466251     0.607702   \n",
       "max       9.939820     4.846452     3.579906     6.634483     3.363685   \n",
       "\n",
       "               V16          V17          V18          V19          V20  \\\n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000   \n",
       "mean     -0.044949    -0.070704    -0.037026    -0.007536    -0.000940   \n",
       "std       1.031225     1.234009     0.894977     0.827070     0.715765   \n",
       "min     -14.129855   -21.338195    -8.484449    -4.038451   -13.421949   \n",
       "25%      -0.490668    -0.490088    -0.508041    -0.471003    -0.212240   \n",
       "50%       0.064560    -0.077191    -0.021247    -0.004843    -0.062039   \n",
       "75%       0.516420     0.389950     0.469353     0.458362     0.124908   \n",
       "max       3.620831     6.024397     3.531250     4.851255    10.150611   \n",
       "\n",
       "               V21          V22          V23          V24          V25  \\\n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000   \n",
       "mean     -0.003516    -0.009421    -0.004147    -0.001200    -0.003314   \n",
       "std       0.756735     0.724749     0.601276     0.599400     0.517363   \n",
       "min     -20.262054    -5.532541   -17.026156    -2.307453    -3.308049   \n",
       "25%      -0.231508    -0.558904    -0.161166    -0.354973    -0.316947   \n",
       "50%      -0.035204    -0.013332    -0.011305     0.038272     0.019200   \n",
       "75%       0.196481     0.509243     0.146835     0.441278     0.348177   \n",
       "max      19.283602     5.805795    13.218751     3.535179     3.590787   \n",
       "\n",
       "               V26          V27          V28       Amount        Class  \n",
       "count  5050.000000  5050.000000  5050.000000  5050.000000  5050.000000  \n",
       "mean     -0.004836    -0.005726     0.002482    86.117232     0.009901  \n",
       "std       0.481913     0.411055     0.302719   227.210259     0.099020  \n",
       "min      -1.715640    -7.976100    -5.048979     0.000000     0.000000  \n",
       "25%      -0.331584    -0.070963    -0.052133     4.990000     0.000000  \n",
       "50%      -0.059882     0.003521     0.012842    20.260000     0.000000  \n",
       "75%       0.228486     0.095662     0.077357    75.000000     0.000000  \n",
       "max       2.961609     4.623508     9.876371  4584.880000     1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5000\n",
       "1      50\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1_2['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Increasing successful detections using data sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df1_2.columns[:-1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5050, 29)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df1_2[labels]\n",
    "X.shape\n",
    "# X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5050,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df1_2['Class']\n",
    "y.shape\n",
    "# y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare_plot(X_resampled, y_resampled, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_resampled: [[ 1.72526466e+00 -1.33725592e+00 -1.01268723e+00 -3.61656463e-01\n",
      "  -1.43161112e+00 -1.09868097e+00 -8.42273887e-01 -2.65944111e-02\n",
      "  -3.24086916e-02  2.15113318e-01  1.61895151e+00 -6.54046265e-01\n",
      "  -1.44266462e+00 -1.54653811e+00 -2.30008313e-01  1.78553942e+00\n",
      "   1.41979301e+00  7.16655170e-02  2.33031136e-01  2.75911462e-01\n",
      "   4.14523549e-01  7.93433622e-01  2.88866295e-02  4.19420877e-01\n",
      "  -3.67528630e-01 -1.55634495e-01 -1.57676763e-02  1.07902703e-02\n",
      "   1.89000000e+02]\n",
      " [ 6.83253845e-01 -1.68187486e+00  5.33349336e-01 -3.26064341e-01\n",
      "  -1.45560260e+00  1.01831722e-01 -5.20590367e-01  1.14036026e-01\n",
      "  -6.01759617e-01  4.44011205e-01  1.52157013e+00  4.99202119e-01\n",
      "  -1.27848981e-01 -2.37253049e-01 -7.52351221e-01  6.67190352e-01\n",
      "   7.24785310e-01 -1.73661453e+00  7.02087839e-01  6.38185555e-01\n",
      "   1.16897942e-01 -3.04605373e-01 -1.25546963e-01  2.44847768e-01\n",
      "   6.91630813e-02 -4.60711621e-01 -1.70682293e-02  6.35420640e-02\n",
      "   3.15170000e+02]]\n",
      "y_resampled: [0 0]\n"
     ]
    }
   ],
   "source": [
    "method = RandomOverSampler()\n",
    "X_resampled, y_resampled = method.fit_sample(X, y)\n",
    "print('X_resampled:', X_resampled[:2])\n",
    "print('y_resampled:', y_resampled[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n",
      "1010\n",
      "4040\n",
      "1010\n"
     ]
    }
   ],
   "source": [
    "'''Define resampling method'''\n",
    "method = SMOTE(kind='borderline1')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "printListItemLength([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7992\n",
      "7992\n"
     ]
    }
   ],
   "source": [
    "'''Apply resampling to training data only'''\n",
    "X_resampled, y_resampled = method.fit_sample(X_train, y_train)\n",
    "\n",
    "printListItemLength([X_resampled, y_resampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_resampled, y_resampled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1004\n",
      "           1       0.75      1.00      0.86         6\n",
      "\n",
      "    accuracy                           1.00      1010\n",
      "   macro avg       0.88      1.00      0.93      1010\n",
      "weighted avg       1.00      1.00      1.00      1010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying SMOTE\n",
    "\n",
    "In this exercise, you're going to re-balance our data using the Synthetic Minority Over-sampling Technique (SMOTE). Unlike ROS, SMOTE does not create exact copies of observations, but creates new, synthetic, samples that are quite similar to the existing observations in the minority class. SMOTE is therefore slightly more sophisticated than just copying observations, so let's apply SMOTE to our credit card data. The dataset df is available and the packages you need for SMOTE are imported. In the following exercise, you'll visualize the result and compare it to the original data, such that you can see the effect of applying SMOTE very clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    X = df.iloc[:, 1:29]\n",
    "    X = np.array(X).astype(np.float)\n",
    "    y = df.iloc[:, 29]\n",
    "    y=np.array(y).astype(np.float)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5050, 28), (5050,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = prep_data(df1_2)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the resampling method\n",
    "method = SMOTE(kind=\"regular\")\n",
    "\n",
    "# Create the resampled feature set\n",
    "X_resampled, y_resampled = method.fit_sample(X, y)\n",
    "\n",
    "def plot_data(X,y):\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.5, linewidth=0.15)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5, linewidth=0.15, c='y')\n",
    "    plt.legend()\n",
    "    return plt.show()\n",
    "\n",
    "plot_data(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare SMOTE to original data\n",
    "\n",
    "In the last exercise, you saw that using SMOTE suddenly gives us more observations of the minority class. Let's compare those results to our original data, to get a good feeling for what has actually happened. Let's have a look at the value counts again of our old and new data, and let's plot the two scatter plots of the data side by side. You'll use the function compare_plot() for that that, which takes the following arguments: X, y, X_resampled, y_resampled, method=''. The function plots your original data in a scatter plot, along with the resampled side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    5000\n",
      "1.0      50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value_counts on the original labels y\n",
    "print(pd.value_counts(pd.Series(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0    5000\n",
      "0.0    5000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the value_counts\n",
    "print(pd.value_counts(pd.Series(y_resampled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_plot(X,y,X_resampled,y_resampled, method):\n",
    "    # Start a plot figure\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # sub-plot number 1, this is our normal data\n",
    "    c0 = ax1.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\",alpha=0.5)\n",
    "    c1 = ax1.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\",alpha=0.5, c='r')\n",
    "    ax1.set_title('Original set')\n",
    "    # sub-plot number 2, this is our oversampled data\n",
    "    ax2.scatter(X_resampled[y_resampled == 0, 0], X_resampled[y_resampled == 0, 1], label=\"Class #0\", alpha=.5)\n",
    "    ax2.scatter(X_resampled[y_resampled == 1, 0], X_resampled[y_resampled == 1, 1], label=\"Class #1\", alpha=.5,c='r')\n",
    "    ax2.set_title(method)\n",
    "    # some settings and ready to go\n",
    "    plt.figlegend((c0, c1), ('Class #0', 'Class #1'), loc='lower center',\n",
    "                  ncol=2, labelspacing=0.)\n",
    "    #plt.tight_layout(pad=3)\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_plot(X, y, X_resampled, y_resampled, method='SMOTE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Fraud detection algorithms in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4040\n",
      "1010\n",
      "4040\n",
      "1010\n"
     ]
    }
   ],
   "source": [
    "'''Split features & labels'''\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "printListItemLength([X_train, X_test, y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02270663, -0.00289419,  0.00284805, ..., -0.00353113,\n",
       "       -0.0111369 ,  0.00095313])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(X_test)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6109901994133817\n"
     ]
    }
   ],
   "source": [
    "print(metrics.r2_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the traditional way to catch fraud\n",
    "\n",
    "In this exercise you're going to try finding fraud cases in our credit card dataset the \"old way\". First you'll define threshold values using common statistics, to split fraud and non-fraud. Then, use those thresholds on your features to detect fraud. This is common practice within fraud analytics teams.\n",
    "\n",
    "Statistical thresholds are often determined by looking at the mean values of observations. Let's start this exercise by checking whether feature means differ between fraud and non-fraud cases. Then, you'll use that information to create common sense thresholds. Finally, you'll check how well this performs in fraud detection.\n",
    "\n",
    "pandas has already been imported as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.035030</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>0.037444</td>\n",
       "      <td>-0.045760</td>\n",
       "      <td>-0.013825</td>\n",
       "      <td>-0.030885</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>-0.022432</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>-0.004511</td>\n",
       "      <td>0.017434</td>\n",
       "      <td>0.004204</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>-0.026640</td>\n",
       "      <td>0.001190</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>-0.010892</td>\n",
       "      <td>-0.016554</td>\n",
       "      <td>-0.002896</td>\n",
       "      <td>-0.010583</td>\n",
       "      <td>-0.010206</td>\n",
       "      <td>-0.003305</td>\n",
       "      <td>-0.000918</td>\n",
       "      <td>-0.002613</td>\n",
       "      <td>-0.004651</td>\n",
       "      <td>-0.009584</td>\n",
       "      <td>0.002414</td>\n",
       "      <td>85.843714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.985211</td>\n",
       "      <td>3.321539</td>\n",
       "      <td>-7.293909</td>\n",
       "      <td>4.827952</td>\n",
       "      <td>-3.326587</td>\n",
       "      <td>-1.591882</td>\n",
       "      <td>-5.776541</td>\n",
       "      <td>1.395058</td>\n",
       "      <td>-2.537728</td>\n",
       "      <td>-5.917934</td>\n",
       "      <td>4.020563</td>\n",
       "      <td>-7.032865</td>\n",
       "      <td>-0.104179</td>\n",
       "      <td>-7.100399</td>\n",
       "      <td>-0.120265</td>\n",
       "      <td>-4.658854</td>\n",
       "      <td>-7.589219</td>\n",
       "      <td>-2.650436</td>\n",
       "      <td>0.894255</td>\n",
       "      <td>0.194580</td>\n",
       "      <td>0.703182</td>\n",
       "      <td>0.069065</td>\n",
       "      <td>-0.088374</td>\n",
       "      <td>-0.029425</td>\n",
       "      <td>-0.073336</td>\n",
       "      <td>-0.023377</td>\n",
       "      <td>0.380072</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>113.469000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "Class                                                                         \n",
       "0      0.035030  0.011553  0.037444 -0.045760 -0.013825 -0.030885  0.014315   \n",
       "1     -4.985211  3.321539 -7.293909  4.827952 -3.326587 -1.591882 -5.776541   \n",
       "\n",
       "             V8        V9       V10       V11       V12       V13       V14  \\\n",
       "Class                                                                         \n",
       "0     -0.022432 -0.002227  0.001667 -0.004511  0.017434  0.004204  0.006542   \n",
       "1      1.395058 -2.537728 -5.917934  4.020563 -7.032865 -0.104179 -7.100399   \n",
       "\n",
       "            V15       V16       V17       V18       V19       V20       V21  \\\n",
       "Class                                                                         \n",
       "0     -0.026640  0.001190  0.004481 -0.010892 -0.016554 -0.002896 -0.010583   \n",
       "1     -0.120265 -4.658854 -7.589219 -2.650436  0.894255  0.194580  0.703182   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \\\n",
       "Class                                                                         \n",
       "0     -0.010206 -0.003305 -0.000918 -0.002613 -0.004651 -0.009584  0.002414   \n",
       "1      0.069065 -0.088374 -0.029425 -0.073336 -0.023377  0.380072  0.009304   \n",
       "\n",
       "           Amount  \n",
       "Class              \n",
       "0       85.843714  \n",
       "1      113.469000  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the mean for each group\n",
    "df1_2.groupby('Class').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Implement a rule for stating which cases are flagged as fraud\n",
    "df1_2['flag_as_fraud'] = np.where(np.logical_and(df1_2['V1']< -3, df1_2['V3']< -5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged Fraud     0   1\n",
      "Actual Fraud           \n",
      "0              4984  16\n",
      "1                28  22\n"
     ]
    }
   ],
   "source": [
    "# Create a crosstab of flagged fraud cases versus the actual fraud cases\n",
    "print(pd.crosstab(df1_2.Class, df1_2.flag_as_fraud, rownames=['Actual Fraud'], colnames=['Flagged Fraud']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ML classification to catch fraud\n",
    "\n",
    "In this exercise you'll see what happens when you use a simple machine learning model on our credit card data instead.\n",
    "\n",
    "Do you think you can beat those results? Remember, you've predicted 22 out of 50 fraud cases, and had 16 false positives.\n",
    "\n",
    "So with that in mind, let's implement a Logistic Regression model. If you have taken the class on supervised learning in Python, you should be familiar with this model. If not, you might want to refresh that at this point. But don't worry, you'll be guided through the structure of the machine learning model.\n",
    "\n",
    "The X and y variables are available in your workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3535, 28), (1515, 28), (3535,), (1515,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit a logistic regression model to our data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain model predictions\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.94      0.90      0.92      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "Confusion matrix:\n",
      " [[1504    1]\n",
      " [   2    8]]\n"
     ]
    }
   ],
   "source": [
    "# Print the classifcation report and confusion matrix\n",
    "print('Classification report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression combined with SMOTE\n",
    "\n",
    "In this exercise, you're going to take the Logistic Regression model from the previous exercise, and combine that with a SMOTE resampling method. We'll show you how to do that efficiently by using a pipeline that combines the resampling method with the model in one go. First, you need to define the pipeline that you're going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pipeline module we need for this from imblearn\n",
    "from imblearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which resampling method and which ML model to use in the pipeline\n",
    "resampling = SMOTE(kind=\"borderline2\")\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline, tell it to combine SMOTE with the Logistic Regression model\n",
    "pipeline = Pipeline([('SMOTE', resampling), ('Logistic Regression', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a pipeline\n",
    "\n",
    "Now that you have our pipeline defined, aka combining a logistic regression with a SMOTE method, let's run it on the data. You can treat the pipeline as if it were a single machine learning model. Our data X and y are already defined, and the pipeline is defined in the previous exercise. Are you curious to find out what the model results are? Let's give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data X and y, into a training and a test set and fit the pipeline onto the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Fit your pipeline onto your training set and obtain predictions by fitting the model onto the test data \n",
    "pipeline.fit(X_train, y_train) \n",
    "predicted = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifcation report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.81      1.00      0.88      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "Confusion matrix:\n",
      " [[1499    6]\n",
      " [   0   10]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the results from the classification report and confusion matrix \n",
    "print('Classifcation report:\\n', classification_report(y_test, predicted))\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=predicted)\n",
    "print('Confusion matrix:\\n', conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Review of classification methods for fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7300 entries, 221547 to 145800\n",
      "Data columns (total 30 columns):\n",
      "V1        7300 non-null float64\n",
      "V2        7300 non-null float64\n",
      "V3        7300 non-null float64\n",
      "V4        7300 non-null float64\n",
      "V5        7300 non-null float64\n",
      "V6        7300 non-null float64\n",
      "V7        7300 non-null float64\n",
      "V8        7300 non-null float64\n",
      "V9        7300 non-null float64\n",
      "V10       7300 non-null float64\n",
      "V11       7300 non-null float64\n",
      "V12       7300 non-null float64\n",
      "V13       7300 non-null float64\n",
      "V14       7300 non-null float64\n",
      "V15       7300 non-null float64\n",
      "V16       7300 non-null float64\n",
      "V17       7300 non-null float64\n",
      "V18       7300 non-null float64\n",
      "V19       7300 non-null float64\n",
      "V20       7300 non-null float64\n",
      "V21       7300 non-null float64\n",
      "V22       7300 non-null float64\n",
      "V23       7300 non-null float64\n",
      "V24       7300 non-null float64\n",
      "V25       7300 non-null float64\n",
      "V26       7300 non-null float64\n",
      "V27       7300 non-null float64\n",
      "V28       7300 non-null float64\n",
      "Amount    7300 non-null float64\n",
      "Class     7300 non-null int64\n",
      "dtypes: float64(29), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df2_1 = pd.read_csv('data/chapter_2/creditcard_sampledata_2.csv', index_col=0)\n",
    "df2_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "labels = df2_1.columns[:-1]\n",
    "X = df2_1[labels]\n",
    "y = df2_1['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993399339933994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predicted = model.predict(X_test)\n",
    "print(metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model.predict_proba(X_test)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural hit rate\n",
    "\n",
    "In this exercise, you'll again use credit card transaction data. The features and labels are similar to the data in the previous chapter, and the data is heavily imbalanced. We've given you features X and labels y to work with already, which are both numpy arrays.\n",
    "\n",
    "First you need to explore how prevalent fraud is in the dataset, to understand what the \"natural accuracy\" is, if we were to predict everything as non-fraud. It's is important to understand which level of \"accuracy\" you need to \"beat\" in order to get a better prediction than by doing nothing. In the following exercises, you'll create our first random forest classifier for fraud detection. That will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7300, 28), (7300,))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = prep_data(df2_1)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7300"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the total number of observations from the length of y\n",
    "total_obs = len(y)\n",
    "total_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the total number of non-fraudulent observations \n",
    "non_fraud = [i for i in y if i==0]\n",
    "count_non_fraud = non_fraud.count(0)\n",
    "count_non_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7000\n",
       "1.0     300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(pd.Series(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.8904109589041\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of non fraud observations in the dataset\n",
    "percentage = (float(count_non_fraud)/float(total_obs)) * 100\n",
    "\n",
    "# Print the percentage: this is our \"natural accuracy\" by doing nothing\n",
    "print(percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier - part 1\n",
    "\n",
    "Let's now create a first random forest classifier for fraud detection. Hopefully you can do better than the baseline accuracy you've just calculated, which was roughly 96%. This model will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises. Let's start first with splitting the data into a test and training set, and defining the Random Forest model. The data available are features X and labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the random forest model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Define the model as the random forest\n",
    "model = RandomForestClassifier(random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier - part 2\n",
    "\n",
    "Let's see how our Random Forest model performs without doing anything special to it. The model from the previous exercise is available, and you've already split your data in X_train, y_train, X_test, y_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9904109589041096\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to our training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predictions from the test data \n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy performance metric\n",
    "print(accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a benefit of using Random Forests versus Decision Trees?\n",
    "\n",
    "Random Forest prevents overfitting most of the time, by creating random subsets of the features and building smaller trees using these subsets. Afterwards, it combines the subtrees of subsamples of features, so it does not tend to overfit to your entire feature set the way \"deep\" Decisions Trees do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Measuring fraud detection performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787512775616596"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision = metrics.average_precision_score(y_test, predicted)\n",
    "average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.04155251, 0.96052632, 1.        ]),\n",
       " array([1.       , 0.8021978, 0.       ]),\n",
       " array([0., 1.]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall, threshold = metrics.precision_recall_curve(y_test, predicted)\n",
    "precision, recall, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874251497005988"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Calculate F1 score'''\n",
    "f1 = metrics.f1_score(y_test, predicted)\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8854716480347339"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Calculate precision-recall AUC'''\n",
    "auc = metrics.auc(recall, precision)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1], [0.5,0.5], linestyle='--')\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2190, 1515]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-177f430a0c4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    353\u001b[0m     return _average_binary_score(\n\u001b[1;32m    354\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         fpr, tpr, _ = roc_curve(y_true, y_score,\n\u001b[0;32m--> 327\u001b[0;31m                                 sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \"\"\"\n\u001b[1;32m    621\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0;32m--> 622\u001b[0;31m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2190, 1515]"
     ]
    }
   ],
   "source": [
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.96      0.80      0.87        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.98      0.90      0.93      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2096    3]\n",
      " [  18   73]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance metrics for the RF model\n",
    "\n",
    "In the previous exercises you obtained an accuracy score for your random forest model. This time, we know accuracy can be misleading in the case of fraud detection. With highly imbalanced fraud data, the AUROC curve is a more reliable performance metric, used to compare different classifiers. Moreover, the classification report tells you about the precision and recall of your model, whilst the confusion matrix actually shows how many fraud cases you can predict correctly. So let's get these performance metrics.\n",
    "\n",
    "You'll continue working on the same random forest model from the previous exercise. Your model, defined as model = RandomForestClassifier(random_state=5) has been fitted to your training data already, and X_train, y_train, X_test, y_test are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the packages to get the different performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9338879319822626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.96      0.80      0.87        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.98      0.90      0.93      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2096    3]\n",
      " [  18   73]]\n"
     ]
    }
   ],
   "source": [
    "# Obtain the predictions from our random forest model \n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print(metrics.roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Precision Recall Curve\n",
    "\n",
    "You can also plot a Precision-Recall curve, to investigate the trade-off between the two in your model. In this curve Precision and Recall are inversely related; as Precision increases, Recall falls and vice-versa. A balance between these two needs to be achieved in your model, otherwise you might end up with many false positives, or not enough actual fraud cases caught. To achieve this and to compare performance, the precision-recall curves come in handy.\n",
    "\n",
    "Your Random Forest Classifier is available as model, and the predictions as predicted. You can simply obtain the average precision score and the PR curve from the sklearn package. The function plot_pr_curve() plots the results for you. Let's give it a try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7787512775616596"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "# Calculate average precision and the PR curve\n",
    "average_precision_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average precision and the PR curve\n",
    "average_precision = average_precision_score(y_test, predicted)\n",
    "\n",
    "# Obtain precision and recall \n",
    "precision, recall, _ = precision_recall_curve(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pr_curve(recall, precision, average_precision):\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the recall precision tradeoff\n",
    "plot_pr_curve(recall, precision, average_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the benefit of the performance metric ROC curve (AUROC) versus Precision and Recall?\n",
    "\n",
    "The key difference between the two performance metrics, is that ROC curves will be the same no matter what the baseline probability is. Precision and Recall may be more useful in practice for needle-in-haystack type problems, or problems where the \"positive\" class is more interesting than the negative class.\n",
    "\n",
    "The ROC curve plots the true positives vs. false positives , for a classifier, as its discrimination threshold is varied. Since, a random method describes a horizontal curve through the unit interval, it has an AUC of 0.5. Minimally, classifiers should perform better than this, and the extent to which they score higher than one another (meaning the area under the ROC curve is larger), they have better expected performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Adjusting your algorithms for fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Balanced weight'''\n",
    "\n",
    "model = RandomForestClassifier(class_weight='balanced')\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample')\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "model = SVC(kernel='linear', class_weight='balanced', probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Hyperparameter tuning for fraud detection'''\n",
    "\n",
    "model = RandomForestClassifier(class_weight={0:1,1:4}, random_state=1)\n",
    "model = LogisticRegression(class_weight={0:1,1:4}, random_state=1)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=None, \n",
    "                               min_samples_split=2,min_samples_leaf=1, \n",
    "                               max_features='auto', n_jobs=-1, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.7 s, sys: 218 ms, total: 5.92 s\n",
      "Wall time: 17min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='f1')\n",
    "grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 90,\n",
       " 'max_features': 3,\n",
       " 'min_samples_leaf': 4,\n",
       " 'min_samples_split': 12,\n",
       " 'n_estimators': 100}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Get the optimal parameters'''\n",
    "grid_search_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=90, max_features=3, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=12,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Get the best estimator results'''\n",
    "grid_search_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89582073397476"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_model.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model adjustments\n",
    "\n",
    "A simple way to adjust the random forest model to deal with highly imbalanced fraud data, is to use the class_weights option when defining your sklearn model. However, as you will see, it is a bit of a blunt force mechanism and might not work for your very special case.\n",
    "\n",
    "In this exercise you'll explore the weight = \"balanced_subsample\" mode the Random Forest model from the earlier exercise. You already have split your data in a training and test set, i.e X_train, X_test, y_train, y_test are available. The metrics function have already been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347962661445273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.99      0.79      0.88        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.99      0.90      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2098    1]\n",
      " [  19   72]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the model with balanced subsample\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample', random_state=5)\n",
    "\n",
    "# Fit your training model to your training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predicted values and probabilities from the model \n",
    "predicted = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the roc_auc_score, the classification report and confusion matrix\n",
    "print(metrics.roc_auc_score(y_test, probs[:, 1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting your Random Forest to fraud detection\n",
    "\n",
    "In this exercise you're going to dive into the options for the random forest classifier, as we'll assign weights and tweak the shape of the decision trees in the forest. You'll define weights manually, to be able to off-set that imbalance slightly. In our case we have 300 fraud to 7000 non-fraud cases, so by setting the weight ratio to 1:12, we get to a 1/3 fraud to 2/3 non-fraud ratio, which is good enough for training the model on.\n",
    "\n",
    "The data in this exercise has already been split into training and test set, so you just need to focus on defining your model. You can then use the function get_model_results() as a short cut. This function fits the model to your training data, predicts and obtains performance metrics similar to the steps you did in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5110, 28), (5110,), (2190, 28), (2190,))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(X_train, y_train, X_test, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    print (classification_report(y_test, predicted))\n",
    "    print (confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.97      0.85      0.91        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.98      0.92      0.95      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2097    2]\n",
      " [  14   77]]\n"
     ]
    }
   ],
   "source": [
    "# Change the model options\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight={0:1, 1:12}, criterion='entropy',\n",
    "    # Change depth of model\n",
    "    max_depth=10,\n",
    "    # Change the number of samples in leaf nodes\n",
    "    min_samples_leaf=10, \n",
    "    # Change the number of trees to use\n",
    "    n_estimators=20, n_jobs=-1, random_state=5)\n",
    "\n",
    "# Run the function get_model_results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV to find optimal parameters\n",
    "\n",
    "In this exercise you're going to tweak our model in a less \"random\" way, but use GridSearchCV to do the work for you.\n",
    "\n",
    "With GridSearchCV you can define which performance metric to score the options on. Since for fraud detection we are mostly interested in catching as many fraud cases as possible, you can optimize your model settings to get the best possible Recall score. If you also cared about reducing the number of false positives, you could optimize on F1-score, this gives you that nice Precision-Recall trade-off.\n",
    "\n",
    "GridSearchCV has already been imported from sklearn.model_selection, so let's give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 8,\n",
       " 'max_features': 'log2',\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameter sets to test\n",
    "param_grid = {'n_estimators': [1, 30], 'max_features': ['auto', 'log2'], \n",
    "              'max_depth': [4, 8], 'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Define the model to use\n",
    "model = RandomForestClassifier(random_state=5)\n",
    "\n",
    "# Combine the parameter sets with the defined model\n",
    "CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "\n",
    "# Fit the model to our training data and obtain best parameters\n",
    "CV_model.fit(X_train, y_train)\n",
    "CV_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model results using GridSearchCV\n",
    "\n",
    "You discovered that the best parameters for your model are that the split criterion should be set to 'gini', the number of estimators (trees) should be 30, the maximum depth of the model should be 8 and the maximum features should be set to \"log2\".\n",
    "\n",
    "Let's give this a try and see how well our model performs. You can use the get_model_results() function again to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.95      0.84      0.89        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.97      0.92      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2095    4]\n",
      " [  15   76]]\n"
     ]
    }
   ],
   "source": [
    "# Input the optimal parameters in the model\n",
    "model = RandomForestClassifier(class_weight={0:1,1:12}, criterion='gini', \n",
    "                               max_depth=8, max_features='log2', \n",
    "                               min_samples_leaf=10, n_estimators=30, \n",
    "                               n_jobs=-1, random_state=5)\n",
    "\n",
    "# Get results from your model\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Using ensemble methods to improve fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_model.fit(X_train, y_train)\n",
    "ensemble_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=1, solver='warn',\n",
       "                                                 tol=0.0001, verbose=0,\n",
       "                                                 warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max...\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     n_estimators='warn',\n",
       "                                                     n_jobs=None,\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=1, verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('gnb',\n",
       "                              GaussianNB(priors=None, var_smoothing=1e-09))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=[2, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "In this last lesson you'll combine three algorithms into one model with the VotingClassifier. This allows us to benefit from the different aspects from all models, and hopefully improve overall performance and detect more fraud. The first model, the Logistic Regression, has a slightly higher recall score than our optimal Random Forest model, but gives a lot more false positives. You'll also add a Decision Tree with balanced weights to it. The data is already split into a training and test set, i.e. X_train, y_train, X_test, y_test are available.\n",
    "\n",
    "In order to understand how the Voting Classifier can potentially improve your original model, you should check the standalone results of the Logistic Regression model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5110, 28), (5110,), (2190, 28), (2190,))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.99      2099\n",
      "         1.0       0.63      0.88      0.73        91\n",
      "\n",
      "    accuracy                           0.97      2190\n",
      "   macro avg       0.81      0.93      0.86      2190\n",
      "weighted avg       0.98      0.97      0.98      2190\n",
      "\n",
      "[[2052   47]\n",
      " [  11   80]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the Logistic Regression model with weights\n",
    "model = LogisticRegression(class_weight={0:1, 1:15}, random_state=5)\n",
    "\n",
    "# Get the model results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier\n",
    "\n",
    "Let's now combine three machine learning models into one, to improve our Random Forest fraud detection model from before. You'll combine our usual Random Forest model, with the Logistic Regression from the previous exercise, with a simple Decision Tree. You can use the short cut get_model_results() to see the immediate result of the ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_results(X_train, y_train, X_test, y_test, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    #probs = model.predict_proba(X_test)\n",
    "    print (classification_report(y_test, predicted))\n",
    "    print (confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      2099\n",
      "         1.0       0.90      0.86      0.88        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.95      0.93      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2090    9]\n",
      " [  13   78]]\n"
     ]
    }
   ],
   "source": [
    "# Import the package\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the three classifiers to use in the ensemble\n",
    "clf1 = LogisticRegression(class_weight={0:1, 1:15}, random_state=5)\n",
    "clf2 = RandomForestClassifier(class_weight={0:1, 1:12}, criterion='gini', max_depth=8, max_features='log2',\n",
    "            min_samples_leaf=10, n_estimators=30, n_jobs=-1, random_state=5)\n",
    "clf3 = DecisionTreeClassifier(random_state=5, class_weight=\"balanced\")\n",
    "\n",
    "# Combine the classifiers in the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='hard')\n",
    "\n",
    "# Get the results \n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression as a standalone was quite bad in terms of false positives, and the Random Forest was worse in terms of false negatives. By combining these together you indeed managed to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust weights within the Voting Classifier\n",
    "\n",
    "You've just seen that the Voting Classifier allows you to improve your fraud detection performance, by combining good aspects from multiple models. Now let's try to adjust the weights we give to these models. By increasing or decreasing weights you can play with how much emphasis you give to a particular model relative to the rest. This comes in handy when a certain model has overall better performance than the rest, but you still want to combine aspects of the others to further improve your results.\n",
    "\n",
    "For this exercise the data is already split into a training and test set, and clf1, clf2 and clf3 are available and defined as before, i.e. they are the Logistic Regression, the Random Forest model and the Decision Tree respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anonymous/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      1.00      2099\n",
      "         1.0       0.94      0.85      0.89        91\n",
      "\n",
      "    accuracy                           0.99      2190\n",
      "   macro avg       0.97      0.92      0.94      2190\n",
      "weighted avg       0.99      0.99      0.99      2190\n",
      "\n",
      "[[2094    5]\n",
      " [  14   77]]\n"
     ]
    }
   ],
   "source": [
    "# Define the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1,4,1], flatten_transform=True)\n",
    "\n",
    "# Get results \n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normal versus abnormal behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7189 entries, 0 to 7199\n",
      "Data columns (total 18 columns):\n",
      "age                      7189 non-null int64\n",
      "amount                   7189 non-null float64\n",
      "fraud                    7189 non-null int64\n",
      "M                        7189 non-null int64\n",
      "es_barsandrestaurants    7189 non-null int64\n",
      "es_contents              7189 non-null int64\n",
      "es_fashion               7189 non-null int64\n",
      "es_food                  7189 non-null int64\n",
      "es_health                7189 non-null int64\n",
      "es_home                  7189 non-null int64\n",
      "es_hotelservices         7189 non-null int64\n",
      "es_hyper                 7189 non-null int64\n",
      "es_leisure               7189 non-null int64\n",
      "es_otherservices         7189 non-null int64\n",
      "es_sportsandtoys         7189 non-null int64\n",
      "es_tech                  7189 non-null int64\n",
      "es_transportation        7189 non-null int64\n",
      "es_travel                7189 non-null int64\n",
      "dtypes: float64(1), int64(17)\n",
      "memory usage: 1.0 MB\n"
     ]
    }
   ],
   "source": [
    "df3_1 = pd.read_csv('data/chapter_3/banksim_adj.csv', index_col=0)\n",
    "df3_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7200 entries, 171915 to 579286\n",
      "Data columns (total 5 columns):\n",
      "age         7200 non-null object\n",
      "gender      7200 non-null object\n",
      "category    7200 non-null object\n",
      "amount      7200 non-null float64\n",
      "fraud       7200 non-null int64\n",
      "dtypes: float64(1), int64(1), object(3)\n",
      "memory usage: 337.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df3_2 = pd.read_csv('data/chapter_3/banksim.csv', index_col=0)\n",
    "df3_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.9, leaf_size=30, metric='euclidean',\n",
       "       metric_params=None, min_samples=10, n_jobs=-1, p=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_3 = pd.read_pickle('data/chapter_3/db_full.pickle')\n",
    "df3_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    0\n",
       "9    0\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_4 = pd.read_pickle('data/chapter_3/labels_full.pickle')\n",
    "df3_4[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6989\n",
       "1     200\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_4.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4656    0\n",
       "3579    0\n",
       "3474    0\n",
       "1501    0\n",
       "6221    0\n",
       "6407    0\n",
       "3823    0\n",
       "471     0\n",
       "705     0\n",
       "3670    0\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_5 = pd.read_pickle('data/chapter_3/labels.pickle')\n",
    "df3_5[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3000\n",
       "1     100\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_5.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83333333, 0.01910336, 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_6 = pd.read_pickle('data/chapter_3/x_scaled.pickle')\n",
    "df3_6[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npValueCounts(Array):\n",
    "    '''\n",
    "    Return numpy array value counts as a pandas dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Array: np.array\n",
    "    \n",
    "    Result\n",
    "    ------\n",
    "    Pandas dataframe\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    unique, counts = np.unique(Array, return_counts=True)\n",
    "    unique_counts = {'value': list(unique), 'count': list(counts)}\n",
    "    df = pd.DataFrame.from_dict(unique_counts)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>42152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2418</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2345</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         value  count\n",
       "0     0.000000  42152\n",
       "2418  1.000000   4621\n",
       "2266  0.333333   1015\n",
       "2345  0.500000    733\n",
       "2380  0.666667    568"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npValueCounts(df3_6).sort_values('count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.20681002, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        ])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_7 = pd.read_pickle('data/chapter_3/x_scawed_full.pickle')\n",
    "df3_7[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>97814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4389</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4218</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4311</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         value  count\n",
       "0     0.000000  97814\n",
       "4389  1.000000  10660\n",
       "4043  0.333333   2333\n",
       "4218  0.500000   1718\n",
       "4311  0.666667   1279"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npValueCounts(df3_7).sort_values('count', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.19166848e+00,  4.28408570e-01,  1.64002800e+00, ...,\n",
       "        -1.74444289e-02,  2.74400000e+01,  0.00000000e+00],\n",
       "       [ 1.96661435e+00, -4.50086974e-01, -1.22858598e+00, ...,\n",
       "        -7.13139301e-02,  3.59500000e+01,  0.00000000e+00],\n",
       "       [ 1.52845161e+00, -1.29619125e+00, -8.90676942e-01, ...,\n",
       "         2.58531705e-02,  2.84000000e+01,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-3.61427839e-01,  1.13347192e+00, -2.97136044e+00, ...,\n",
       "        -1.82750897e-01,  4.80720000e+02,  1.00000000e+00],\n",
       "       [-1.14155894e+00,  1.92765004e+00, -3.90535615e+00, ...,\n",
       "         7.62114891e-02,  2.50000000e+01,  1.00000000e+00],\n",
       "       [-4.19820174e-01, -1.15597801e+00, -2.09251550e+00, ...,\n",
       "         1.29096386e-01,  4.51270000e+02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(df2_1).astype(np.float)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "       n_clusters=6, n_init=10, n_jobs=None, precompute_distances='auto',\n",
       "       random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans = KMeans(n_clusters=6, random_state=42).fit(X_scaled)\n",
    "kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right amount of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1319.2623146279884,\n",
       " -871.8713924662665,\n",
       " -793.9142667605355,\n",
       " -716.0272968299423,\n",
       " -677.0290872392054,\n",
       " -648.3118453906632,\n",
       " -625.8925978268425,\n",
       " -605.7337776364698,\n",
       " -590.1229051372973]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = range(1, 10)\n",
    "kmeans = [KMeans(n_clusters=i) for i in clust]\n",
    "score = [kmeans[i].fit(X_scaled).score(X_scaled) for i in range(len(kmeans))]\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elbow curve\n",
    "https://en.wikipedia.org/wiki/Elbow_method_(clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(clust, score)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1. Assigning fraud versus non-fraud cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.30326930e-01, 6.58013592e-01, 8.91470119e-01, 2.98407174e-01,\n",
       "        6.92995753e-01, 2.82662755e-01, 6.24293301e-01, 6.71913254e-01,\n",
       "        6.21410867e-01, 6.57172707e-01, 2.13714726e-01, 8.21587445e-01,\n",
       "        6.40461703e-01, 7.51479815e-01, 4.61797435e-01, 7.47403860e-01,\n",
       "        7.90010560e-01, 7.15702852e-01, 4.11181295e-01, 4.15243600e-01,\n",
       "        4.55688047e-01, 5.15915167e-01, 5.70856861e-01, 4.42200154e-01,\n",
       "        5.55857570e-01, 3.07185390e-01, 5.91225691e-01, 2.06097679e-01,\n",
       "        6.38904901e-03, 8.32667268e-16],\n",
       "       [5.93629587e-01, 7.76159313e-01, 4.66089637e-01, 7.38119523e-01,\n",
       "        4.69359978e-01, 1.99511101e-01, 4.29328142e-01, 7.32125494e-01,\n",
       "        3.65008859e-01, 3.42534520e-01, 6.42077015e-01, 2.93650009e-01,\n",
       "        5.69009804e-01, 3.36421711e-01, 5.23892602e-01, 2.65218646e-01,\n",
       "        2.89380840e-01, 2.61405305e-01, 6.22649766e-01, 4.33037091e-01,\n",
       "        4.63099879e-01, 5.40090616e-01, 5.70164465e-01, 4.56836705e-01,\n",
       "        5.63387771e-01, 3.53058735e-01, 5.89787121e-01, 2.02402024e-01,\n",
       "        6.10235772e-03, 1.00000000e+00],\n",
       "       [9.23178887e-01, 6.54468199e-01, 8.91436587e-01, 2.69242292e-01,\n",
       "        6.92724181e-01, 2.89754290e-01, 6.25398760e-01, 6.71979987e-01,\n",
       "        6.28286006e-01, 6.54427156e-01, 2.14001010e-01, 8.31033964e-01,\n",
       "        5.03879047e-01, 7.48477206e-01, 5.57992108e-01, 7.36012615e-01,\n",
       "        7.87044644e-01, 7.15435238e-01, 3.91139092e-01, 4.16039393e-01,\n",
       "        4.56599230e-01, 5.11640524e-01, 5.70784367e-01, 4.60378128e-01,\n",
       "        5.58318556e-01, 4.90828683e-01, 5.88026053e-01, 2.05453181e-01,\n",
       "        9.23218459e-03, 7.28583860e-16],\n",
       "       [9.30043767e-01, 6.57185854e-01, 8.95056408e-01, 3.01423118e-01,\n",
       "        6.94061484e-01, 2.86957458e-01, 6.23980410e-01, 6.72912191e-01,\n",
       "        6.15337936e-01, 6.56719129e-01, 2.05549237e-01, 8.29989987e-01,\n",
       "        5.67535200e-01, 7.44813406e-01, 6.58044485e-01, 7.49228732e-01,\n",
       "        7.88305549e-01, 7.12745185e-01, 4.18675759e-01, 4.15713925e-01,\n",
       "        4.56092269e-01, 5.18058238e-01, 5.69532355e-01, 4.65550732e-01,\n",
       "        5.61173526e-01, 3.02143828e-01, 5.89086541e-01, 2.05771309e-01,\n",
       "        6.44333421e-03, 9.02056208e-16],\n",
       "       [9.31236168e-01, 6.56551090e-01, 8.91867569e-01, 2.99131243e-01,\n",
       "        6.91857763e-01, 2.77870974e-01, 6.24521656e-01, 6.71872796e-01,\n",
       "        6.22080895e-01, 6.56760719e-01, 2.13766787e-01, 8.17823045e-01,\n",
       "        3.78383523e-01, 7.53068136e-01, 5.37693724e-01, 7.49414937e-01,\n",
       "        7.89216727e-01, 7.17574677e-01, 4.13657836e-01, 4.15175769e-01,\n",
       "        4.55800513e-01, 5.17368612e-01, 5.70160905e-01, 4.37724256e-01,\n",
       "        5.58416231e-01, 3.06078304e-01, 5.90582725e-01, 2.05813528e-01,\n",
       "        6.33271899e-03, 8.88178420e-16],\n",
       "       [8.76291178e-01, 6.84622610e-01, 7.94077800e-01, 4.69718732e-01,\n",
       "        6.75511709e-01, 2.56865453e-01, 5.95378677e-01, 6.63791060e-01,\n",
       "        5.62053080e-01, 5.75875841e-01, 3.73709507e-01, 6.58476642e-01,\n",
       "        4.86925629e-01, 5.45079664e-01, 5.69591651e-01, 6.33017809e-01,\n",
       "        6.94672118e-01, 6.60382033e-01, 4.49925922e-01, 4.18076013e-01,\n",
       "        4.74372121e-01, 5.11301904e-01, 5.70132127e-01, 4.32432372e-01,\n",
       "        5.56831934e-01, 3.36634730e-01, 6.04330582e-01, 2.14681627e-01,\n",
       "        1.08701575e-02, 1.00000000e+00]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Run KMeans model on scaled data'''\n",
    "kmeans = KMeans(n_clusters=6, random_state=42, n_jobs=-1).fit(X_scaled)\n",
    "\n",
    "'''Get the cluster number for each datapoint'''\n",
    "X_clusters = kmeans.predict(X_scaled)\n",
    "\n",
    "'''Save the cluster centroids'''\n",
    "X_clusters_centers = kmeans.cluster_centers_\n",
    "\n",
    "X_clusters_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31791654367137306,\n",
       " 0.1967040711444739,\n",
       " 0.28072073181670354,\n",
       " 0.21838338765292928,\n",
       " 0.42462893827920384,\n",
       " 0.25127538063448873,\n",
       " 0.18103219252833663,\n",
       " 0.37287074790805236,\n",
       " 0.21988456413718224,\n",
       " 0.17842344034158075]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Calculate the distance to the cluster centroid for each point'''\n",
    "dist = [np.linalg.norm(x-y) for x,y in zip(X_scaled, X_clusters_centers[X_clusters])]\n",
    "\n",
    "dist[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Create predictions based on distance'''\n",
    "km_y_pred = np.array(dist)\n",
    "km_y_pred[dist >= np.percentile(dist, 93)] = 1\n",
    "km_y_pred[dist < np.percentile(dist, 93)] = 0\n",
    "\n",
    "km_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  count\n",
       "0    0.0   6789\n",
       "1    1.0    511"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npValueCounts(km_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Other clustering fraud detection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=0.5, leaf_size=30, metric='euclidean',\n",
       "       metric_params=None, min_samples=10, n_jobs=-1, p=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DBSCAN(eps=0.5, min_samples=10, n_jobs=-1).fit(X_scaled)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Get the cluster labels'''\n",
    "pred_labels = db.labels_\n",
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   value  count\n",
       "0     -1     37\n",
       "1      0   6983\n",
       "2      1    223\n",
       "3      2     12\n",
       "4      3     45"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npValueCounts(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Count the total number of clusters'''\n",
    "n_clusters_ = len(set(pred_labels)) - (1 if -1 in pred_labels else 0)\n",
    "n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 4\n"
     ]
    }
   ],
   "source": [
    "print('Estimated number of clusters: %d' % n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient: 0.645\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette coefficient: %0.3f' % metrics.silhouette_score(X_scaled, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using text data to detect fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 2),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 2),\n",
       " (5, 1),\n",
       " (6, 2),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 5),\n",
       " (11, 2),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 4),\n",
       " (27, 2),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 3),\n",
       " (32, 4),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 3),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1),\n",
       " (40, 3),\n",
       " (41, 2),\n",
       " (42, 1),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 4),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 1),\n",
       " (51, 1),\n",
       " (52, 1),\n",
       " (53, 2),\n",
       " (54, 1),\n",
       " (55, 1),\n",
       " (56, 1),\n",
       " (57, 3),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 2),\n",
       " (61, 1),\n",
       " (62, 2),\n",
       " (63, 1),\n",
       " (64, 1),\n",
       " (65, 1),\n",
       " (66, 1),\n",
       " (67, 3),\n",
       " (68, 7),\n",
       " (69, 1),\n",
       " (70, 2),\n",
       " (71, 1),\n",
       " (72, 2),\n",
       " (73, 1),\n",
       " (74, 1),\n",
       " (75, 1),\n",
       " (76, 1),\n",
       " (77, 1),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 1),\n",
       " (85, 1),\n",
       " (86, 3),\n",
       " (87, 1),\n",
       " (88, 1),\n",
       " (89, 1),\n",
       " (90, 2),\n",
       " (91, 2),\n",
       " (92, 2),\n",
       " (93, 1),\n",
       " (94, 1),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 1),\n",
       " (100, 1),\n",
       " (101, 1),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 2),\n",
       " (108, 1),\n",
       " (109, 2),\n",
       " (110, 1),\n",
       " (111, 1),\n",
       " (112, 1),\n",
       " (113, 1),\n",
       " (114, 1),\n",
       " (115, 1),\n",
       " (116, 3),\n",
       " (117, 1),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 1),\n",
       " (121, 1),\n",
       " (122, 1),\n",
       " (123, 1),\n",
       " (124, 2),\n",
       " (125, 1)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_1 = pd.read_pickle('data/chapter_4/corpus.pickle')\n",
    "print(type(df4_1))\n",
    "print(len(df4_1))\n",
    "df4_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.corpora.dictionary.Dictionary'>\n",
      "8948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'affiliated'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_2 = pd.read_pickle('data/chapter_4/dict.pickle')\n",
    "print(type(df4_2))\n",
    "print(len(df4_2))\n",
    "df4_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2090 entries, 0 to 2089\n",
      "Data columns (total 6 columns):\n",
      "Message-ID       2090 non-null object\n",
      "From             2090 non-null object\n",
      "To               2090 non-null object\n",
      "Date             2090 non-null object\n",
      "content          2090 non-null object\n",
      "clean_content    2086 non-null object\n",
      "dtypes: object(6)\n",
      "memory usage: 98.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df4_3 = pd.read_csv('data/chapter_4/enron_emails_clean.csv')\n",
    "df4_3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;8345058.1075840404046.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>2002-01-29 23:20:55</td>\n",
       "      <td>INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...</td>\n",
       "      <td>investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Message-ID  \\\n",
       "0  <8345058.1075840404046.JavaMail.evans@thyme>   \n",
       "\n",
       "                              From                               To  \\\n",
       "0  ('advdfeedback@investools.com')  ('advdfeedback@investools.com')   \n",
       "\n",
       "                  Date  \\\n",
       "0  2002-01-29 23:20:55   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               content  \\\n",
       "0  INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         clean_content  \n",
       "0  investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2090\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3['content'].str.contains('money laundering').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1866\n",
       "True      224\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3['content'].str.contains('money').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2088\n",
       "True        2\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3['content'].str.contains('launder').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message-ID       2\n",
       "From             2\n",
       "To               2\n",
       "Date             2\n",
       "content          2\n",
       "clean_content    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3.loc[df4_3['content'].str.contains('launder', na=False)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2081\n",
       "True        9\n",
       "Name: content, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_words = ['police', 'launder']\n",
    "df4_3['content'].str.contains('|'.join(list_of_words), na=False).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1. Text mining techniques for fraud detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.73 s, sys: 33.8 ms, total: 4.77 s\n",
      "Wall time: 4.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "'''Tokenization'''\n",
    "# text = df4_3.apply(lambda row: word_tokenize(row['content']), axis=1)\n",
    "# text = text.str.rstrip()\n",
    "# text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "\n",
    "df4_3['text'] = df4_3['content'].str.rstrip()\n",
    "df4_3['text'] = df4_3['text'].str.replace(r'[^a-zA-Z]', ' ')\n",
    "df4_3['text'] = df4_3.apply(lambda row: word_tokenize(row['text']), axis=1)\n",
    "text = df4_3['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;8345058.1075840404046.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>2002-01-29 23:20:55</td>\n",
       "      <td>INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...</td>\n",
       "      <td>investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...</td>\n",
       "      <td>[INVESTools, Advisory, A, Free, Digest, of, Trusted, Investment, Advice, To, unsubscribe, from, this, free, newsletter, please, see, below, In, This, Issue, Fried, Sells, Stocks, Gains, in, Months, KM, Rowe, January, Index, Confirms, Bull, Market, for, ALOY, Small, Cap, Advisor, Earns, in, LBIX, Compounding, Returns, with, Pine, Trees, PCL, Undervalued, High, yield, Bank, Puts, Customers, First, ASO, A, Word, from, our, Sponsor, Top, Wall, Street, Watcher, Ben, Zacks, year, Year, Gain, Movin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Message-ID  \\\n",
       "0  <8345058.1075840404046.JavaMail.evans@thyme>   \n",
       "\n",
       "                              From                               To  \\\n",
       "0  ('advdfeedback@investools.com')  ('advdfeedback@investools.com')   \n",
       "\n",
       "                  Date  \\\n",
       "0  2002-01-29 23:20:55   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               content  \\\n",
       "0  INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         clean_content  \\\n",
       "0  investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0  [INVESTools, Advisory, A, Free, Digest, of, Trusted, Investment, Advice, To, unsubscribe, from, this, free, newsletter, please, see, below, In, This, Issue, Fried, Sells, Stocks, Gains, in, Months, KM, Rowe, January, Index, Confirms, Bull, Market, for, ALOY, Small, Cap, Advisor, Earns, in, LBIX, Compounding, Returns, with, Pine, Trees, PCL, Undervalued, High, yield, Bank, Puts, Customers, First, ASO, A, Word, from, our, Sponsor, Top, Wall, Street, Watcher, Ben, Zacks, year, Year, Gain, Movin...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"'\", '_', ';', '{', '>', ',', '}', '`', ':', ']', '-', '!', '%', '[', '\\\\', '?', '/', '&', '+', '~', '(', '|', '*', '#', '@', '.', '<', '\"', '$', '^', ')', '='}\n"
     ]
    }
   ],
   "source": [
    "'''Remove all stopwords and punctuation'''\n",
    "exclude = set(string.punctuation)\n",
    "print(exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'couldn', 'from', 'the', \"you'd\", 'such', 'has', 'yours', 'with', 'same', 'they', 'myself', 'have', 'doesn', 'it', 'under', 'haven', \"it's\", 'while', 'm', 'we', 'hasn', 'when', 'am', 'both', 'most', \"won't\", \"hasn't\", 'other', 'being', 'doing', 'above', 'o', 'about', 'ourselves', \"shouldn't\", 'shouldn', 'having', 's', 'was', 'wouldn', 'hers', 'so', 'herself', 'very', 'she', 'he', 'a', 'can', 'shan', 'down', 'whom', 'again', 'these', 'does', \"mightn't\", 'before', 'himself', 'by', 'not', \"don't\", 'further', 'nor', 'at', 'than', 'yourself', 'over', 'where', 'which', 'wasn', 'that', 'as', 'i', 're', 'did', 'just', \"weren't\", 'my', 'do', 'd', 'their', 'had', 'once', 'but', 'our', 'there', 'why', 'won', \"should've\", 'aren', \"shan't\", 've', 'ain', 'to', 'what', 'ma', 'only', 'and', 'his', 'during', \"you'll\", 'll', \"she's\", 'an', 'hadn', \"you're\", 'isn', 'weren', 'some', 'all', 'or', 'few', 'don', \"aren't\", 'should', 'mightn', 'theirs', 'its', 'themselves', \"wouldn't\", 't', 'more', 'itself', 'yourselves', 'here', 'between', 'is', 'in', 'any', \"isn't\", 'after', 'y', 'needn', 'now', \"wasn't\", 'of', \"you've\", 'below', 'been', 'him', 'own', \"couldn't\", 'then', \"mustn't\", 'this', 'were', 'those', 'be', 'through', 'your', 'if', 'didn', 'no', \"doesn't\", 'them', 'how', 'until', 'too', 'off', 'are', \"haven't\", 'who', 'each', 'because', 'her', 'on', 'into', 'ours', 'out', 'for', 'mustn', \"hadn't\", \"didn't\", \"needn't\", 'me', 'against', 'you', 'will', \"that'll\", 'up'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwarded Forwarded Forwarded Forwarded Forwarded Forwarded Forwarded Forwarded Forwarded Forwarded \n"
     ]
    }
   ],
   "source": [
    "stop_free = ' '.join([word for word in lis for lis in text if ((word not in stop) and (not word.isdigit()))])\n",
    "\n",
    "# for lis in text:\n",
    "#     for word in lis:\n",
    "#         if (word not in stop) and (not word.isdigit()):\n",
    "#             stop_free = ' '.join([word])\n",
    "\n",
    "print(stop_free[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Lemmatize words'''\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "'''Stem words'''\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message-ID</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Date</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;8345058.1075840404046.JavaMail.evans@thyme&gt;</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>('advdfeedback@investools.com')</td>\n",
       "      <td>2002-01-29 23:20:55</td>\n",
       "      <td>INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...</td>\n",
       "      <td>investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...</td>\n",
       "      <td>[INVESTools, Advisory, A, Free, Digest, of, Trusted, Investment, Advice, To, unsubscribe, from, this, free, newsletter, please, see, below, In, This, Issue, Fried, Sells, Stocks, Gains, in, Months, KM, Rowe, January, Index, Confirms, Bull, Market, for, ALOY, Small, Cap, Advisor, Earns, in, LBIX, Compounding, Returns, with, Pine, Trees, PCL, Undervalued, High, yield, Bank, Puts, Customers, First, ASO, A, Word, from, our, Sponsor, Top, Wall, Street, Watcher, Ben, Zacks, year, Year, Gain, Movin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Message-ID  \\\n",
       "0  <8345058.1075840404046.JavaMail.evans@thyme>   \n",
       "\n",
       "                              From                               To  \\\n",
       "0  ('advdfeedback@investools.com')  ('advdfeedback@investools.com')   \n",
       "\n",
       "                  Date  \\\n",
       "0  2002-01-29 23:20:55   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               content  \\\n",
       "0  INVESTools Advisory\\nA Free Digest of Trusted Investment Advice\\n\\nTo unsubscribe from this free newsletter, please see below.\\n\\nIn This Issue:\\n\\n1. Fried Sells 4 Stocks, Gains +46.8% in 3 Months (KM)\\n2. Rowe: January Index Confirms Bull Market for 2002 (ALOY)\\n3. Small-Cap Advisor Earns +31.6% in 2001 (LBIX)\\n4. Compounding Returns with Pine Trees (PCL)\\n5. Undervalued, High-yield Bank Puts Customers First (ASO)\\n\\n\\n*************** A Word from our Sponsor *******************\\nTop Wall S...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         clean_content  \\\n",
       "0  investools advisory free digest trusted investment advice unsubscribe free newsletter please see issue fried sells stocks gains months km rowe january index confirms bull market aloy small cap advisor earns lbix compounding returns pine trees pcl undervalued high yield bank puts customers first aso word sponsor top wall street watcher ben zacks year year gain moving best brightest wall street big money machines earned ben zacks five year average annual gain start outperforming long term get ...   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  \n",
       "0  [INVESTools, Advisory, A, Free, Digest, of, Trusted, Investment, Advice, To, unsubscribe, from, this, free, newsletter, please, see, below, In, This, Issue, Fried, Sells, Stocks, Gains, in, Months, KM, Rowe, January, Index, Confirms, Bull, Market, for, ALOY, Small, Cap, Advisor, Earns, in, LBIX, Compounding, Returns, with, Pine, Trees, PCL, Undervalued, High, yield, Bank, Puts, Customers, First, ASO, A, Word, from, our, Sponsor, Top, Wall, Street, Watcher, Ben, Zacks, year, Year, Gain, Movin...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4_3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.corpora.dictionary.Dictionary"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dictionary number of times a word appears\n",
    "dictionary = corpora.Dictionary(df4_3['text'])\n",
    "type(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out (non)frequent words\n",
    "dictionary.filter_extremes(no_below=5, keep_n=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"Return first n items of the iterable as a list\"\n",
    "    return list(islice(iterable, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 10),\n",
       " (0, 402),\n",
       " (41, 31),\n",
       " (63, 21),\n",
       " (2, 6),\n",
       " (539, 66),\n",
       " (255, 888),\n",
       " (254, 154),\n",
       " (371, 35),\n",
       " (411, 488)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take(10, dictionary.dfs.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324309"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724142"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary.num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 370 ms, sys: 4.08 ms, total: 374 ms\n",
      "Wall time: 372 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in df4_3['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2090"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Dirichlet Allocation (LDA) with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Define the LDA model'''\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = 3, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Print the 3 topics from the model with top words'''\n",
    "topics = ldamodel.print_topics(num_words=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.035*\"com\" + 0.030*\"http\" + 0.023*\"net\" + 0.022*\"IMAGE\"')\n",
      "(1, '0.021*\"ECT\" + 0.014*\"Enron\" + 0.014*\"ENRON\" + 0.013*\"Subject\"')\n",
      "(2, '0.015*\"s\" + 0.015*\"Enron\" + 0.012*\"com\" + 0.009*\"or\"')\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3. Flagging fraud based on topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_details(ldamodel, corpus):\n",
    "    topic_details_df = pd.DataFrame()\n",
    "    \n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        \n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            '''dominant topic'''\n",
    "            if j == 0:\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_details_df = topic_details_df.append(pd.Series([topic_num, wp]))\n",
    "    \n",
    "    topic_details_df.columns = ['Dominant_Topic', '% Score']\n",
    "    \n",
    "    return topic_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents = pd.DataFrame({'Original text': text_clean})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
